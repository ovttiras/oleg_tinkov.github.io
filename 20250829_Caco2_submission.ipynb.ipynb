{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18466480-482f-4086-98f5-c7ead0a545ed",
   "metadata": {},
   "source": [
    "# TDC ADMET, Caco-2_Wang Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c86952a-47f8-4e3d-a22e-36ecfe207217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# cheminformatics\n",
    "import rdkit.Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# logging\n",
    "import tqdm\n",
    "\n",
    "# data preprocessing\n",
    "import sklearn.impute\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# modeling\n",
    "import sklearn.ensemble\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# metrics\n",
    "import sklearn.metrics\n",
    "\n",
    "from tdc.single_pred import ADME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee27599-741d-4e64-a737-e71ec9094266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "100%|██████████| 82.5k/82.5k [00:00<00:00, 305kiB/s]\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = ADME(name = 'Caco2_Wang')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ea5838-436a-44e0-add0-549ff410ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_descriptor_columns(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Use rdkit to get descriptors of each drug in the `data` df.\n",
    "    Return a Pandas DataFrame with the descriptors as columns in the df and .\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the Drug column\n",
    "    assert 'Drug' in data.columns, \"'Drug' must be a column in the input DataFrame.\"\n",
    "    drugs = data['Drug']\n",
    "    y = data['Y']\n",
    "    \n",
    "    # Get the descriptors for each drug\n",
    "    print(\"Calculating descriptors...\")\n",
    "    descriptors = []\n",
    "    for drug, target in tqdm.tqdm(zip(drugs, y)):\n",
    "        descriptor = Descriptors.CalcMolDescriptors(\n",
    "            rdkit.Chem.MolFromSmiles(drug)\n",
    "        )\n",
    "        descriptor['Drug'] = drug\n",
    "        descriptor['Y'] = target\n",
    "        descriptors.append(descriptor)\n",
    "\n",
    "    # Make a dataframe for the descriptors\n",
    "    df = pd.DataFrame(descriptors)\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_data(\n",
    "    data: pd.DataFrame, \n",
    "    imputer=sklearn.impute.SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "    fit_imputer=True,\n",
    "    scaler_X=sklearn.preprocessing.RobustScaler(),\n",
    "    scaler_y=sklearn.preprocessing.RobustScaler(),\n",
    "    fit_scaler=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Imputes missing values.\n",
    "    Scales feature data.\n",
    "\n",
    "    Returns a tuple X, y of scaled feature data and target data.\n",
    "    \"\"\"\n",
    "\n",
    "    col_array = np.array(data.columns)\n",
    "\n",
    "    # extract just the feature data\n",
    "    X = data[col_array[~np.isin(col_array, ['Drug_ID', 'Drug', 'Y'])]].to_numpy()\n",
    "    \n",
    "    # extract the target data\n",
    "    y = np.array(data['Y']).reshape(-1,1)\n",
    "    \n",
    "    # impute missing data\n",
    "    if imputer is not None:\n",
    "        if fit_imputer:\n",
    "            X = imputer.fit_transform(X)\n",
    "        else:\n",
    "            X = imputer.transform(X)\n",
    "\n",
    "    # scale the feature data\n",
    "    if scaler_X is not None:\n",
    "        if fit_scaler:\n",
    "            X = scaler_X.fit_transform(X)\n",
    "            y = scaler_y.fit_transform(y)\n",
    "        else:\n",
    "            X = scaler_X.transform(X)\n",
    "            y = scaler_y.transform(y)\n",
    "\n",
    "\n",
    "\n",
    "    return X, y, imputer, scaler_X, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6010f6-e6e6-4c7d-ae76-f608faef7d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "637it [00:07, 86.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:00, 97.14it/s] \n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Предобработка данных\n",
    "X_train, y_train, imputer, scaler_X, scaler_y = preprocess_data(\n",
    "    add_descriptor_columns(split['train'])\n",
    ")\n",
    "X_val, y_val, _, _, _ = preprocess_data(\n",
    "    add_descriptor_columns(split['valid']),\n",
    "    imputer=imputer, fit_imputer=False,\n",
    "    scaler_X=scaler_X, scaler_y=scaler_y,\n",
    "    fit_scaler=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa9b3c7-0671-4583-b443-efd93e7fbab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search: 100%|██████████| 2048/2048 [34:18<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 0.27487999368926663\n",
      "Best params: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0.3, 'reg_lambda': 1.2, 'scale_pos_weight': 2, 'subsample': 0.7}\n",
      "Best num_boost_round: 208\n",
      "Модель и параметры сохранены в model/Cacao2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Создаем папку для модели, если нет\n",
    "model_dir = \"model/Cacao2\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Преобразуем данные в DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train.ravel())\n",
    "dval = xgb.DMatrix(X_val, label=y_val.ravel())\n",
    "\n",
    "# Сетка параметров\n",
    "params_grid = {'subsample': [0.7, 0.8],\n",
    "    'scale_pos_weight': [2, 3],   \n",
    "    'reg_lambda': [1.0, 1.2],\n",
    "    'reg_alpha': [0.3, 0.5],\n",
    "    'n_estimators': [200, 300],  \n",
    "    'min_child_weight': [1, 2],\n",
    "    'max_depth': [7, 9],         \n",
    "    'max_delta_step': [2, 3],\n",
    "    'learning_rate': [0.03, 0.05],\n",
    "    'gamma': [0.1, 0.2],\n",
    "    'colsample_bytree': [0.7, 0.8]}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_set = {}\n",
    "best_num_boost_round = 0\n",
    "best_model = None\n",
    "\n",
    "for param_set in tqdm(ParameterGrid(params_grid), desc=\"Grid Search\"):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 42,\n",
    "        'eval_metric': 'mae',\n",
    "        'tree_method': 'gpu_hist',  # Используем GPU\n",
    "        'gpu_id': 0,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    params.update(param_set)\n",
    "\n",
    "    evals = [(dtrain, 'train'), (dval, 'eval')]\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    y_val_pred_tmp = model.predict(dval)\n",
    "    score_MAE = mean_absolute_error(y_val, y_val_pred_tmp)\n",
    "\n",
    "    if score_MAE < best_score:\n",
    "        best_score = score_MAE\n",
    "        best_set = param_set\n",
    "        best_num_boost_round = model.best_iteration\n",
    "        best_model = model\n",
    "\n",
    "# Сохраняем лучшую модель\n",
    "model_path = os.path.join(model_dir, \"best_model.xgb\")\n",
    "best_model.save_model(model_path)\n",
    "\n",
    "# Сохраняем параметры лучшей модели\n",
    "params_path = os.path.join(model_dir, \"best_params.json\")\n",
    "with open(params_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"best_score\": best_score,\n",
    "        \"best_params\": best_set,\n",
    "        \"best_num_boost_round\": best_num_boost_round\n",
    "    }, f, indent=4)\n",
    "\n",
    "print(\"Best MAE:\", best_score)\n",
    "print(\"Best params:\", best_set)\n",
    "print(\"Best num_boost_round:\", best_num_boost_round)\n",
    "print(f\"Модель и параметры сохранены в {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "498a5655-04c8-42c7-913d-7e5e7748513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:08, 90.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:02, 84.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 2:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:08, 88.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:02, 87.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 3:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:08, 87.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:02, 84.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 4:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:08, 84.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:02, 80.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 5:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:08, 84.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:02, 79.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'caco2_wang': [0.272, 0.006]}\n"
     ]
    }
   ],
   "source": [
    "from tdc.benchmark_group import admet_group\n",
    "import tqdm\n",
    "\n",
    "group = admet_group(path='data/')\n",
    "predictions_list = []\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    benchmark = group.get('Caco2_Wang') \n",
    "    predictions = {}\n",
    "    name = benchmark['name']\n",
    "\n",
    "    # используем весь train_val для обучения\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "\n",
    "    print(f\"Seed {seed}:\")\n",
    "\n",
    "    # ---------------- Предобработка ---------------- #\n",
    "    X_train, y_train, imputer, scaler_X, scaler_y = preprocess_data(\n",
    "        add_descriptor_columns(train_val)\n",
    "    )\n",
    "    X_test, y_test, _, _, _ = preprocess_data(\n",
    "        add_descriptor_columns(test),\n",
    "        imputer=imputer, fit_imputer=False,\n",
    "        scaler_X=scaler_X, fit_scaler=False,\n",
    "        scaler_y=scaler_y\n",
    "    )\n",
    "\n",
    "    # ---------------- XGBoost ---------------- #\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train.ravel())\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    params = best_set.copy()\n",
    "    params.update({\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': seed,\n",
    "        'eval_metric': 'mae'\n",
    "    })\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=best_num_boost_round\n",
    "    )\n",
    "\n",
    "    # ---------------- Предсказания ---------------- #\n",
    "    y_pred_test_scaled = model.predict(dtest)\n",
    "    y_pred_test = scaler_y.inverse_transform(\n",
    "        y_pred_test_scaled.reshape(-1, 1)\n",
    "    ).reshape(-1)\n",
    "\n",
    "    # сохраняем по TDC-шаблону\n",
    "    predictions[name] = y_pred_test\n",
    "    predictions_list.append(predictions)\n",
    "\n",
    "# ---------------- Оценка ---------------- #\n",
    "results = group.evaluate_many(predictions_list)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0cb39-08f4-449f-8aac-ce93bee5e434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
